{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from skimage.transform import resize\n",
    "import scipy.stats as stats\n",
    "import matplotlib.image\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "from PIL import Image\n",
    "from scipy.stats import pearsonr\n",
    "import h5py\n",
    "import scipy.io as sio\n",
    "\n",
    "folder_path = \"/path/to/your/data/\"\n",
    "# The V4 map data can be downloaded from: https://zenodo.org/records/10972034"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V4 digital twin image preference map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the top-9 images of each grid in the V4 digital twin\n",
    "features = np.load(folder_path + \"V4DT/PRsp.npy\")\n",
    "features = np.transpose(features, (2, 1, 0)) # (128, 128, 50000)\n",
    "features = np.swapaxes(features, 0, 1)\n",
    "grid_num = int(features.shape[0])\n",
    "roi = np.load(folder_path + \"V4DT/ROI.npy\").T # 3048 roi voxels\n",
    "# define the size of a single image\n",
    "img_size = 30\n",
    "line_width = 5\n",
    "top_img_num = 9\n",
    "# create a blank map of black color (R=0, G=0, B=0)\n",
    "map = np.zeros((grid_num * (img_size*3 + line_width) + line_width,\n",
    "                grid_num * (img_size*3 + line_width) + line_width, \n",
    "                3))\n",
    "grid_top_images = np.zeros((grid_num, grid_num, top_img_num)) # store the top 9 images of each grid\n",
    "# fill the map with the images\n",
    "for i in tqdm(range(grid_num), desc=\"map initialization...\", disable=False):\n",
    "    for j in range(grid_num):\n",
    "            if roi[i, j] == 1:\n",
    "                # 1-indexed image names\n",
    "                image_label = np.arange(50000) + 1 # or \"labels + 1\" if features were selected from the top-3 responsive images\n",
    "                # sort the mean responses (from small to large) and the image_label according to the order of mean responses\n",
    "                _, image_label = zip(*sorted(zip(features[i, j, :],image_label)))\n",
    "                # take the top nine images with largest mean response\n",
    "                image_label = np.flip(image_label[-top_img_num:])\n",
    "                # store the 0-indexed 9 imgs of each grid\n",
    "                grid_top_images[i, j, :] = (image_label - 1).astype(int)\n",
    "                # locate the top left corner of the current grid in the map\n",
    "                x = i * (img_size*3 + line_width) + line_width\n",
    "                y = j * (img_size*3 + line_width) + line_width\n",
    "                # fill the map's current grid with the selected nine images\n",
    "                for row in range(3):\n",
    "                    for col in range(3):    \n",
    "                        # load the image\n",
    "                        path = folder_path + \"50K_Imgset/\" + str(int(image_label[row*3+col])) + \".bmp\" # the image name is 1-indexed\n",
    "                        img = np.array(Image.open(path))[20:80, 20:80, :] # obtain the non-blurred central part of the image\n",
    "                        img = resize(img, (img_size, img_size, 3), anti_aliasing=True) # resize the image\n",
    "                        img = np.fliplr(np.flipud(img)) # flip the image vertically and horizontally\n",
    "                        # put the image onto the map\n",
    "                        map[x + (2 - row) * img_size : x + ((2 - row) + 1) * img_size, \n",
    "                            y + (2 - col) * img_size : y + ((2 - col) + 1) * img_size, \n",
    "                            :] = img\n",
    "            else:\n",
    "                # fill the map's current grid with pure white color\n",
    "                x = i * (img_size*3 + line_width)\n",
    "                y = j * (img_size*3 + line_width)\n",
    "                map[x : x + img_size*3 + line_width*2, y : y + img_size*3 + line_width*2, :] = 1.0\n",
    "map = np.fliplr(np.flipud(map)) # top-bottom flip and then left-right flip\n",
    "size = (img_size*3 + line_width)\n",
    "map = map[38*size:114*size, 38*size:105*size, :] # only keep the roi part\n",
    "map_save_path = folder_path + \"Fig1/V4_DT_full.bmp\"\n",
    "np.save(folder_path + \"V4DT/top9_0index.npy\", grid_top_images)\n",
    "matplotlib.image.imsave(map_save_path, map)\n",
    "del features, map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce map size\n",
    "image = Image.open(folder_path + \"Fig1/V4_DT_full.bmp\")\n",
    "width, height = image.size\n",
    "factor = 3\n",
    "resized_image = image.resize((int(np.round(width/factor)), int(np.round(height/factor))), Image.Resampling.LANCZOS)\n",
    "resized_image.save(folder_path + \"Fig1/V4_DT.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of RSOM training from V4 digital twin neuronal columns' tuning curves + estimated retinotopic positions\n",
    "# visualize the V4 data ROI shape\n",
    "roi = np.load(folder_path + \"V4DT/ROI.npy\").T # (128, 128) <class 'numpy.ndarray'>\n",
    "roi = np.flip(roi)\n",
    "roi = roi[37:115, 37:106]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "cmap = colors.ListedColormap(['white', 'lightyellow'])  # 0 for white, 1 for lightyellow\n",
    "ax.imshow(roi, cmap=cmap, interpolation='none')\n",
    "roi_grid = np.ma.masked_where(roi == 0, roi) # Create a masked array to only apply grid where roi is 1\n",
    "# Add grid lines only for the region of interest\n",
    "for i in range(roi.shape[0]):\n",
    "    for j in range(roi.shape[1]):\n",
    "        if roi[i, j] == 1:  # Only show grid for ROI entries with value 1\n",
    "            ax.plot([j-0.5, j+0.5], [i-0.5, i-0.5], color='black', linestyle='--', linewidth=0.5)  # Top line\n",
    "            ax.plot([j-0.5, j+0.5], [i+0.5, i+0.5], color='black', linestyle='--', linewidth=0.5)  # Bottom line\n",
    "            ax.plot([j-0.5, j-0.5], [i-0.5, i+0.5], color='black', linestyle='--', linewidth=0.5)  # Left line\n",
    "            ax.plot([j+0.5, j+0.5], [i-0.5, i+0.5], color='black', linestyle='--', linewidth=0.5)  # Right line\n",
    "# Add contour lines for the region of interest with a 3D effect (using multiple levels and shadowing)\n",
    "contour = ax.contour(roi, levels=[0.5], colors='black', linewidths=2, alpha=0.9)\n",
    "# Adding additional contour for 3D effect (shadow)\n",
    "ax.contour(roi, levels=[0.5], colors='gray', linewidths=6, alpha=0.75, linestyles='solid')\n",
    "# Remove axis labels and ticks\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# Remove the axis box\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(folder_path + \"Fig1/ROI.png\", dpi=1000)\n",
    "plt.close()\n",
    "\n",
    "# Create a 60 by 60 grid to visualize the SOM map\n",
    "rows, cols = 60, 60\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(4, 4))  # Adjust figsize for higher resolution\n",
    "# Plot the grid\n",
    "for x in range(rows + 1):\n",
    "    ax.plot([x, x], [0, cols], color='black', linewidth=0.5)\n",
    "for y in range(cols + 1):\n",
    "    ax.plot([0, rows], [y, y], color='black', linewidth=0.5)\n",
    "# Set the aspect of the plot to be equal\n",
    "ax.set_aspect('equal')\n",
    "# Set limits to match grid size\n",
    "ax.set_xlim(0, rows)\n",
    "ax.set_ylim(0, cols)\n",
    "# Turn off axes ticks\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# Save as high resolution\n",
    "plt.savefig(folder_path + \"Fig1/grids.png\", dpi=3000)  # Save the image in high resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V4 digital twin shape-texture image preference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This subsection is contributed by Yingjue Bian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    # just use CPU\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import applications, regularizers, optimizers, activations\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation, Flatten, Cropping2D,ReLU\n",
    "from tensorflow.keras.layers import SeparableConv2D, Add, Reshape, Permute, LocallyConnected2D, Conv2DTranspose\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "# import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import scipy.io as sio\n",
    "\n",
    "def load_and_resize_images(folder_path, target_size=(50, 50)):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                img = Image.open(img_path).resize(target_size) # grayscale images\n",
    "                # print(img)\n",
    "                # 转换为RGB格式，确保无论格式如何都有三通道\n",
    "                img = img.convert(\"RGB\")\n",
    "                img_array = np.array(img)  # 转换为NumPy数组，形状为 (100, 100, 3)\n",
    "                # print(img_array)\n",
    "                # Create a new white canvas of (100, 100)\n",
    "                padded_image = np.full((100, 100, 3), 255, dtype=np.uint8)\n",
    "                # Calculate padding offsets\n",
    "                x_offset = (100 - target_size[0]) // 2\n",
    "                y_offset = (100 - target_size[1]) // 2\n",
    "    # Place the resized image onto the white canvas\n",
    "                padded_image[y_offset:y_offset + target_size[0], x_offset:x_offset + target_size[1]] = img_array\n",
    "                images.append(padded_image)  # 将处理后的NumPy数组添加到列表中\n",
    "            except IOError:\n",
    "                print(f\"无法读取图片文件: {filename}\")\n",
    "    # 将所有图片堆叠成四维数组\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "# 使用方法\n",
    "texture_path = r\"TextureStimuli\"\n",
    "shape_path = r\"ShapeStimuli\"\n",
    "\n",
    "textureimages = load_and_resize_images(texture_path, target_size=(50, 50))\n",
    "shapeimages = load_and_resize_images(shape_path, target_size=(50, 50))\n",
    "shapeimageset = load_and_resize_images(shape_path, target_size=(100, 100))\n",
    "textureimageset = load_and_resize_images(texture_path, target_size=(100, 100))\n",
    "\n",
    "shape_num = shapeimages.shape[0]\n",
    "texture_num = textureimages.shape[0]\n",
    "\n",
    "images = np.concatenate([textureimages, shapeimages], axis=0)\n",
    "imageset = np.concatenate([textureimageset, shapeimageset], axis=0)\n",
    "\n",
    "sio.savemat('imgset.mat', {'imgset': imageset.astype('float32')/255})\n",
    "\n",
    "num = images.shape[0]\n",
    "\n",
    "# print(num)\n",
    "#%% model setting\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.InteractiveSession(config=config)\n",
    "\n",
    "image_input = Input(shape=(100,100,3))\n",
    "x = Conv2D(64, (5, 5),strides=(1,1))(image_input)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(activations.sigmoid)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "x = Conv2D(100, (3, 3),strides=(1,1))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(activations.sigmoid)(x)\n",
    "x = SeparableConv2D(100,(3,3),strides=(1,1))(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(activations.sigmoid)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "residual = Conv2D(200, (1, 1), strides=(1, 1), padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "x = SeparableConv2D(200,(3,3),strides=(1,1), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(activations.sigmoid)(x)\n",
    "x = SeparableConv2D(200,(3,3),strides=(1,1), padding='same')(x)\n",
    "x = Add()([x, residual])\n",
    "x = Activation(activations.sigmoid)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "residual = Conv2D(400, (1, 1), strides=(1, 1), padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "x = SeparableConv2D(400,(3,3),strides=(1,1), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(activations.sigmoid)(x)\n",
    "x = SeparableConv2D(400,(3,3),strides=(1,1), padding='same')(x)\n",
    "x = Add()([x, residual])\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Activation(activations.sigmoid)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "residual = x\n",
    "x = SeparableConv2D(400,(3,3),strides=(1,1), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(activations.sigmoid)(x)\n",
    "x = SeparableConv2D(400,(3,3),strides=(1,1), padding='same')(x)\n",
    "x = Add()([x, residual])\n",
    "x = Activation(activations.sigmoid)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Cropping2D(cropping=((2, 2), (2, 2)))(x)\n",
    "\n",
    "x = Reshape((49,20,20))(x)\n",
    "x = Permute((2, 3, 1))(x)\n",
    "x = Conv2D(32, (3, 3),strides=(1,1))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(activations.sigmoid)(x)\n",
    "x = LocallyConnected2D(16, (3,3), implementation =1)(x)\n",
    "x = Activation(activations.sigmoid)(x)\n",
    "x = Conv2D(64, (3, 3),strides=(1,1), padding='same')(x)\n",
    "\n",
    "x = Conv2DTranspose(1,(8,8),strides = (8,8))(x)\n",
    "x = LocallyConnected2D(1, (1,1), implementation =3)(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "model = Model(inputs = image_input, outputs = x)\n",
    "\n",
    "### The Conv2DTranspose is only used for reshaping the feature map\n",
    "w1 = model.layers[-3].get_weights()\n",
    "w2 = np.zeros((8, 8, 1, 64))\n",
    "ni = 0\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        w2[i,j,0,ni] = 1\n",
    "        ni = ni+1\n",
    "w1[0] = w2\n",
    "w1[1][0] = 0\n",
    "model.layers[-3].set_weights(w1)\n",
    "model.layers[-3].trainable = False\n",
    "\n",
    "# weight = h5py.File()\n",
    "# print(model.summary())\n",
    "model.load_weights(folder_path + \"V4DT/best_model.hdf5\")\n",
    "\n",
    "# print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "#%% inference\n",
    "# import gc\n",
    "\n",
    "# batch_size = 2\n",
    "# num_batches = len(images) // batch_size\n",
    "# PRsp_list = []\n",
    "# for i in range(num_batches):\n",
    "#     batch = images[i * batch_size : (i + 1) * batch_size]\n",
    "#     batch_output = model.predict(batch)\n",
    "#     PRsp_list.append(batch_output)\n",
    "#     # tf.keras.backend.clear_session()  \n",
    "#     del batch, batch_output  \n",
    "#     gc.collect() \n",
    "\n",
    "# if len(images) % batch_size != 0:\n",
    "#     batch = images[num_batches * batch_size:]\n",
    "#     batch_output = model.predict(batch)\n",
    "#     PRsp_list.append(batch_output)\n",
    "#     del batch, batch_output \n",
    "#     gc.collect()\n",
    "\n",
    "# PRsp = np.concatenate(PRsp_list, axis=0)\n",
    "# # PRsp = np.reshape(PRsp,(num,128,128)) \n",
    "PRsp = model.predict(images,batch_size=2) # 需要分batch处理，否则预测错误\n",
    "\n",
    "PRsp = np.reshape(PRsp,(num,128,128))\n",
    "sio.savemat('PRsp.mat', {'PRsp':PRsp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the top-9 shape and texture images of each grid in the V4 digital twin\n",
    "STimg = sio.loadmat(folder_path + \"V4DT/ST_imgset.mat\")[\"imgset\"] # (814, 100, 100, 3): 448 texture + 366 shape image stimuli\n",
    "# (814, 128, 128): 128 by 128 V4 digital twin responses to 814 shape and texture image stimuli\n",
    "features = sio.loadmat(folder_path + \"V4DT/ST_PRsp.mat\")[\"PRsp\"]\n",
    "grid_num = int(features.shape[1])\n",
    "stmap = np.ones((grid_num, grid_num)) # 1 for shape preferring, 2 for texture preferring\n",
    "assert grid_num == features.shape[2]\n",
    "roi = np.load(folder_path + \"V4DT/ROI.npy\").T # 3048 roi voxels\n",
    "# define the size of a single image\n",
    "img_size = 30\n",
    "line_width = 5\n",
    "top_img_num = 9\n",
    "# create a blank map of black color (R=0, G=0, B=0)\n",
    "map = np.zeros((grid_num * (img_size*3 + line_width) + line_width,\n",
    "                grid_num * (img_size*3 + line_width) + line_width, \n",
    "                3))\n",
    "# fill the map with the images\n",
    "for i in tqdm(range(grid_num), desc=\"map initialization...\", disable=False):\n",
    "    for j in range(grid_num):\n",
    "            if roi[i, j] == 1:\n",
    "                image_label = np.arange(814) # 0-indexed top preferred images\n",
    "                # sort the mean responses (from small to large) and the image_label according to the order of mean responses\n",
    "                _, image_label = zip(*sorted(zip(features[:, i, j], image_label)))\n",
    "                # take the top nine images with largest mean response\n",
    "                image_label = np.flip(image_label[-top_img_num:])\n",
    "                # locate the top left corner of the current grid in the map\n",
    "                x = i * (img_size*3 + line_width) + line_width\n",
    "                y = j * (img_size*3 + line_width) + line_width\n",
    "                # fill the map's current grid with the selected nine images\n",
    "                texture_img_count = 0\n",
    "                for row in range(3):\n",
    "                    for col in range(3):    \n",
    "                        # load the image\n",
    "                        img = STimg[int(image_label[row*3+col])][20:80, 20:80, :] # obtain the non-blurred central part of the image\n",
    "                        img = resize(img, (img_size, img_size, 3), anti_aliasing=True) # resize the image\n",
    "                        img = np.fliplr(np.flipud(img)) # flip the image vertically and horizontally\n",
    "                        # put the image onto the map\n",
    "                        map[x + (2 - row) * img_size : x + ((2 - row) + 1) * img_size, \n",
    "                            y + (2 - col) * img_size : y + ((2 - col) + 1) * img_size, \n",
    "                            :] = img\n",
    "                        if image_label[row*3+col] < 448: texture_img_count += 1 # texture image\n",
    "                if texture_img_count > 4: stmap[i, j] = 2 # the current pixel is texture preferring\n",
    "            else:\n",
    "                stmap[i, j] = 0\n",
    "                # fill the map's current grid with pure white color\n",
    "                x = i * (img_size*3 + line_width)\n",
    "                y = j * (img_size*3 + line_width)\n",
    "                map[x : x + img_size*3 + line_width*2, y : y + img_size*3 + line_width*2, :] = 1.0\n",
    "print(\"texture preferring ratio:\", np.sum(stmap == 2) / np.sum(stmap != 0)) # V4 digital twin: 0.447\n",
    "np.save(folder_path + \"Fig1/V4_stmap.npy\", stmap) # 0 for non-ROI, 1 for shape preferring, 2 for texture preferring\n",
    "map = np.fliplr(np.flipud(map)) # top-bottom flip and then left-right flip\n",
    "size = (img_size*3 + line_width)\n",
    "map = map[38*size:114*size, 38*size:105*size, :] # only keep the roi part\n",
    "map_save_path = folder_path + \"Fig1/V4_ST.png\"\n",
    "matplotlib.image.imsave(map_save_path, map)\n",
    "del features, map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_to_100(FD, Min, Max):\n",
    "    # 计算 Imap\n",
    "    Imap = np.floor((FD - Min) / (Max - Min) * 100)\n",
    "        # 确保 Imap 中的值不小于1\n",
    "    Imap = np.where(Imap < 1, 1, Imap)\n",
    "        # 确保 Imap 中的值不大于100\n",
    "    Imap = np.where(Imap > 100, 100, Imap)\n",
    "  \n",
    "    return Imap/100\n",
    "\n",
    "texture_num = N1 = 448\n",
    "shape_num = N2 = 366\n",
    "\n",
    "Rsp = sio.loadmat(folder_path + \"V4DT/ST_PRsp.mat\")\n",
    "PRsp_data = Rsp['PRsp']\n",
    "Rsp = Rsp['PRsp']\n",
    "Rsp = Rsp[:N1+N2,:,:]\n",
    "\n",
    "texture_PRsp = PRsp_data[0:texture_num, :,:]  # 448 textures\n",
    "shape_PRsp = PRsp_data[texture_num:texture_num + shape_num, :,:]  # 366 shapes\n",
    "ROI_transpose = np.load(folder_path + \"V4DT/ROI.npy\").T\n",
    "roi_indices = np.argwhere(ROI_transpose == 1)  \n",
    "roi_data = Rsp*ROI_transpose\n",
    "\n",
    "num_neurons = roi_indices.shape[0]\n",
    "spersity_1 = np.zeros((128,128))\n",
    "\n",
    "num =  int((N1 + N2)*0.15)\n",
    "# num = 25\n",
    "\n",
    "for i in range(num_neurons):\n",
    "    response = roi_data[:,roi_indices[i,0],roi_indices[i,1]]\n",
    "    top_1percent_indices = np.argsort(response)[-num:]\n",
    "\n",
    "    texture_count_1 = np.sum(top_1percent_indices < N1)\n",
    "    shape_count_1 = np.sum(top_1percent_indices >= N1)\n",
    "\n",
    "    # print(texture_count,shape_count) \n",
    "    spersity_1[roi_indices[i,0],roi_indices[i,1]] = texture_count_1/num\n",
    "\n",
    "V4FD = sio.loadmat(folder_path + \"V4DT/Dispersity_results/FDraw.mat\")['FD']\n",
    "V4FD = normalize_to_100(V4FD, 0, 1)\n",
    "\n",
    "spersity_nan_1 = np.where(ROI_transpose>0,spersity_1,np.nan)\n",
    "spersity_nan_flat = spersity_nan_1.flatten()\n",
    "spersity_nan_1 = np.flip(spersity_nan_1)\n",
    "\n",
    "plt.imshow(spersity_nan_1,cmap='Spectral')\n",
    "plt.colorbar()\n",
    "# plt.show()\n",
    "# plt.imsave('texture_shape_map.png', spersity_nan_1, cmap='Spectral',vmin=0,vmax=1)\n",
    "\n",
    "spersity_flat = spersity_1.flatten()\n",
    "V4FD_flat = V4FD.flatten()\n",
    "valid_mask = ~np.isnan(spersity_nan_flat)\n",
    "\n",
    "r, p_value = stats.pearsonr(spersity_flat[valid_mask], V4FD_flat[valid_mask])\n",
    "print(f\"Pearson r: {r}, p-value: {p_value}\")\n",
    "print(f\"cosine similarity: {np.dot(spersity_flat[valid_mask],V4FD_flat[valid_mask])/(np.linalg.norm(spersity_flat[valid_mask])*np.linalg.norm(V4FD_flat[valid_mask]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOM():\n",
    "    \"\"\"\n",
    "    2-D Self-Organizing Map with Gaussian Neighbourhood function and linearly decreasing learning rate.\n",
    "    \"\"\"\n",
    "    def __init__(self, m, n, dim, niter, alpha=None, sigma=None, decay_rate=0.5, theta=1, tqdm_disable=False):\n",
    "        self.device = torch.device('mps' if torch.backends.mps.is_built() else 'cpu')\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.dim = dim\n",
    "        self.niter = niter\n",
    "        self.alpha = float(alpha) if alpha is not None else 0.5\n",
    "        self.sigma = float(sigma) if sigma is not None else max(m, n) / 60.0 # given m = n = 60, default sigma = 5\n",
    "        self.decay_rate = decay_rate # learning rate decay rate\n",
    "        self.decay_steps = 10\n",
    "        self.tqdm_disable = tqdm_disable\n",
    "\n",
    "        self.positions = False\n",
    "        self.theta = theta if theta is not None else 1\n",
    "        self.positions_weighted = torch.cat((torch.full((50000,), self.theta), torch.full((2,), 125.0))).to(self.device)\n",
    "        self.normalize = False\n",
    "\n",
    "        # Initialize and normalize weights\n",
    "        self.weights = torch.nn.functional.normalize(torch.rand((m * n, dim), device=self.device), p=2, dim=1)\n",
    "        self.locations = torch.tensor(list(self.neuron_locations()), device=self.device)\n",
    "        self.pdist = nn.PairwiseDistance(p=2).to(self.device)\n",
    "\n",
    "    def neuron_locations(self):\n",
    "        for i in range(self.m):\n",
    "            for j in range(self.n):\n",
    "                yield [i, j]\n",
    "\n",
    "    def forward(self, x, it):\n",
    "        \"\"\"\n",
    "        x = x.to(self.device) # to be normalized\n",
    "        if self.normalize: # normalize input vector's response to 50k images only to give a unit vector with l2 norm = 1\n",
    "            if self.positions:\n",
    "                x[:-2] = torch.nn.functional.normalize(x[:-2], p=2, dim=0)\n",
    "            else:\n",
    "                x = torch.nn.functional.normalize(x, p=2, dim=0)\n",
    "        \"\"\"\n",
    "        # pairwise distances between input vector and all som neurons: torch.Size([m * n])\n",
    "        if self.positions:\n",
    "            stacked = torch.stack([x for i in range(self.m*self.n)]) * self.positions_weighted\n",
    "            dists = self.pdist(stacked, self.weights)\n",
    "        else:\n",
    "            stacked = torch.stack([x for i in range(self.m*self.n)])\n",
    "            dists = self.pdist(stacked, self.weights)\n",
    "        _, bmu_index = torch.min(dists, 0)\n",
    "        bmu_loc = self.locations[bmu_index,:].squeeze()\n",
    "        \n",
    "        # decreasing lr step wise over iterations\n",
    "        # alpha_op = self.alpha * self.decay_rate ** (it // self.decay_steps) # 1.0 - it / self.niter; try with no constant lr for all iterations\n",
    "        alpha_op = self.alpha # constant lr\n",
    "        sigma_op = self.sigma - (self.decay_rate * (it // self.decay_steps))\n",
    "        sigma_op = 1.0 if sigma_op <= 1.0 else sigma_op\n",
    "\n",
    "        # distance calculation\n",
    "        bmu_distance_squares = torch.sum(torch.pow(self.locations.float() - torch.stack([bmu_loc for i in range(self.m*self.n)]).float(), 2), 1)\n",
    "        neighbourhood_func = torch.exp(torch.neg(torch.div(bmu_distance_squares, sigma_op**2)))\n",
    "        learning_rate_op = alpha_op * neighbourhood_func\n",
    "\n",
    "        learning_rate_multiplier = torch.stack([learning_rate_op[i:i+1].repeat(self.dim) for i in range(self.m*self.n)])\n",
    "        delta = torch.mul(learning_rate_multiplier, (stacked - self.weights))\n",
    "        self.weights = torch.add(self.weights, delta)\n",
    "\n",
    "    def train(self, data):\n",
    "        data = torch.tensor(data, device=self.device, dtype=torch.float32)\n",
    "        if self.normalize:\n",
    "            for i in tqdm(range(data.shape[0]), desc=\"Normalizing Data 1st 50k entries...\"):\n",
    "                if self.positions:\n",
    "                    data[i, :-int(data.shape[1] - 50000)] = torch.nn.functional.normalize(data[i, :-int(data.shape[1] - 50000)], p=2, dim=0)\n",
    "                else:\n",
    "                    data[i, :] = torch.nn.functional.normalize(data[i, :], p=2, dim=0)\n",
    "        for iteration in range(self.niter):\n",
    "            for i in tqdm(range(data.shape[0]), desc=f\"{1+iteration}th Iteration in Progress...\"):\n",
    "                self.forward(data[i, :], iteration)\n",
    "\n",
    "# Create a V4twin_rsp matrix of shape (3048, 50000) for SOM training\n",
    "def load_data(position=False): \n",
    "    response = np.load(folder_path + \"V4DT/PRsp.npy\") # (50000, 128, 128)\n",
    "    roi = np.load(folder_path + \"V4DT/ROI.npy\").T # (128, 128) # Transpose is crucial! This matches the \"roi\" with \"response\"\n",
    "    if position:\n",
    "        theta = sio.loadmat(folder_path + \"V4DT/RF_results/theta_map_raw.mat\")['theta_map_raw'] # (128, 128)\n",
    "        r = sio.loadmat(folder_path + \"V4DT/RF_results/r_map_raw.mat\")['r_map_raw'] # (128, 128)\n",
    "        # Initialize data array: (N, 50000 + 2)\n",
    "        # The extra 2 columns are for 'r' and 'theta'\n",
    "        data = np.zeros((np.sum(roi), response.shape[0] + 2))\n",
    "        \n",
    "        entry = 0\n",
    "        for i in range(roi.shape[0]):\n",
    "            for j in range(roi.shape[1]):\n",
    "                if roi[i, j] == 1:\n",
    "                    # 1. Copy the 50k response features\n",
    "                    data[entry, :-2] = response[:, i, j]\n",
    "                    \n",
    "                    # 2. Append the position features (r, theta)\n",
    "                    data[entry, -2] = r[i, j]\n",
    "                    data[entry, -1] = theta[i, j]\n",
    "                    \n",
    "                    entry += 1\n",
    "    else:\n",
    "        data = np.zeros((np.sum(roi), response.shape[0]))\n",
    "        entry = 0\n",
    "        for i in range(roi.shape[0]):\n",
    "            for j in range(roi.shape[1]):\n",
    "                if roi[i, j] == 1:\n",
    "                    data[entry, :] = response[:, i, j]\n",
    "                    entry += 1\n",
    "    assert entry == data.shape[0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som = SOM(60, 60, 50000, 120, alpha=0.5, sigma=5, decay_rate=0.5, theta=1, tqdm_disable=False)\n",
    "som.train(load_data(position=False))\n",
    "som_weights = som.weights.cpu().detach().numpy()\n",
    "print(\"SOM training completed, with SOM weight:\", som_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsom = SOM(60, 60, 50002, 120, alpha=0.5, sigma=5, decay_rate=0.5, theta=1, tqdm_disable=False)\n",
    "rsom.positions = True # Important: Enable the position flag manually\n",
    "rsom.train(load_data(position=True))\n",
    "rsom_weights = rsom.weights.cpu().detach().numpy()\n",
    "print(\"RSOM training completed, with RSOM weight:\", rsom_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSOM image preference map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"RSOM\"  # or \"SOM\", folder to the trained RSOM or SOM model\n",
    "features = np.load(folder_path + name + \"/weights.npy\") # (60, 60, 50000(+))\n",
    "if features.shape[2] > 50000:\n",
    "    features = features[:, :, :-int(features.shape[2] - 50000)] # remove positional information from the data\n",
    "    assert features.shape[2] == 50000\n",
    "# define the size of a single image\n",
    "grid_num = 60\n",
    "img_size = 30\n",
    "line_width = 5\n",
    "top_img_num = 9\n",
    "roi = np.ones((grid_num, grid_num)) # all grids are roi\n",
    "# create a blank map of black color (R=0, G=0, B=0)\n",
    "map = np.zeros((grid_num * (img_size*3 + line_width) + line_width,\n",
    "                grid_num * (img_size*3 + line_width) + line_width, \n",
    "                3))\n",
    "grid_top_images = np.zeros((grid_num, grid_num, top_img_num)) # store the top 9 images of each grid\n",
    "# fill the map with the images\n",
    "for i in tqdm(range(grid_num), desc=\"map initialization...\", disable=False):\n",
    "    for j in range(grid_num):\n",
    "            if roi[i, j] == 1:\n",
    "                # 1-indexed image names\n",
    "                image_label = np.arange(50000) + 1 # or \"labels + 1\" if features were selected from the top-3 responsive images\n",
    "                # sort the mean responses (from small to large) and the image_label according to the order of mean responses\n",
    "                _, image_label = zip(*sorted(zip(features[i, j, :],image_label)))\n",
    "                # take the top nine images with largest mean response\n",
    "                image_label = np.flip(image_label[-top_img_num:])\n",
    "                # store the 0-indexed 9 imgs of each grid\n",
    "                grid_top_images[i, j, :] = (image_label - 1).astype(int)\n",
    "                # locate the top left corner of the current grid in the map, map transposed, map is transposed here\n",
    "                x = j * (img_size*3 + line_width) + line_width\n",
    "                y = i * (img_size*3 + line_width) + line_width\n",
    "                # fill the map's current grid with the selected nine images\n",
    "                for row in range(3):\n",
    "                    for col in range(3): \n",
    "                        # load the image\n",
    "                        path = folder_path + \"50K_Imgset/\" + str(int(image_label[row*3+col])) + \".bmp\" # the image name is 1-indexed\n",
    "                        img = np.array(Image.open(path))[20:80, 20:80, :] # obtain the non-blurred central part of the image\n",
    "                        img = resize(img, (img_size, img_size, 3), anti_aliasing=True) # resize the image\n",
    "                        # put the image onto the map\n",
    "                        map[x + (2 - row) * img_size : x + ((2 - row) + 1) * img_size, \n",
    "                            y + (2 - col) * img_size : y + ((2 - col) + 1) * img_size, \n",
    "                            :] = img\n",
    "np.save(folder_path + name + \"/rsptop_0index.npy\", grid_top_images)\n",
    "matplotlib.image.imsave(folder_path + \"Fig1/RSOM.jpg\", map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dispersity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dispersity\n",
    "dispersity = sio.loadmat(folder_path + \"V4DT/Dispersity_results/dispersity.mat\")['cmap'] # (128, 128, 3) <class 'numpy.ndarray'>\n",
    "dispersity_raw = sio.loadmat(folder_path + \"V4DT/Dispersity_results/FDraw.mat\")[\"FD\"]\n",
    "\n",
    "# load roi\n",
    "roi = np.load(folder_path + \"V4DT/ROI.npy\").T # (128, 128) <class 'numpy.ndarray'>\n",
    "\n",
    "# load predicted responses to both texture and shape images\n",
    "PRsp = sio.loadmat(folder_path + \"V4DT/ST_PRsp.mat\")[\"PRsp\"]\n",
    "texture_num = 448\n",
    "shape_num = 366\n",
    "texture_PRsp = PRsp[0:texture_num, :,:]  # texture imgs, (448, 128, 128)\n",
    "texture_PRsp = np.mean(texture_PRsp, axis=0)\n",
    "texture_PRsp[np.where(roi!=1)] = 0\n",
    "shape_PRsp = PRsp[texture_num:texture_num + shape_num, :,:]  # shape imgs, (366, 128, 128)\n",
    "shape_PRsp = np.mean(shape_PRsp, axis=0)\n",
    "shape_PRsp[np.where(roi!=1)] = 0\n",
    "ts_ratio = (texture_PRsp + 1) / (shape_PRsp + 1) - 1 # texture_mean_response / shape_mean_response\n",
    "\n",
    "# visualization\n",
    "fig, axes = plt.subplots(1, 6, figsize=(12, 2))\n",
    "axes[0].imshow(np.flip(roi[10:100, 20:95]))\n",
    "axes[0].axis('off')  # Turn off the axis\n",
    "axes[0].set_title('ROI')\n",
    "axes[1].imshow(np.flip(texture_PRsp[10:100, 20:95]))\n",
    "axes[1].axis('off')  # Turn off the axis\n",
    "axes[1].set_title('texture')\n",
    "axes[2].imshow(np.flip(shape_PRsp[10:100, 20:95]))\n",
    "axes[2].axis('off')  # Turn off the axis\n",
    "axes[2].set_title('shape')\n",
    "axes[3].imshow(np.flip(ts_ratio[10:100, 20:95]))\n",
    "axes[3].axis(\"off\")\n",
    "axes[3].set_title('texture/shape')\n",
    "axes[4].imshow(np.flip(dispersity, axis=(0, 1))[30:120, 35:110, :])\n",
    "axes[4].axis('off')  # Turn off the axis\n",
    "axes[4].set_title('dispersity')\n",
    "axes[5].imshow(np.flip(dispersity_raw)[30:120, 35:110])\n",
    "axes[5].axis('off')  # Turn off the axis\n",
    "axes[5].set_title('dispersity_raw')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize V4 feature dispersity map\n",
    "d = dispersity\n",
    "d[roi!=1] = 1\n",
    "plt.imshow(np.flip(d, axis=(0, 1))[30:120, 35:110, :])\n",
    "plt.axis('off')  # Turn off the axis\n",
    "plt.tight_layout()\n",
    "plt.savefig(folder_path + \"Fig1/dispersity.png\", dpi=1000)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example images associated with different feature dispersity values\n",
    "d = dispersity_raw[roi!=0].flatten()\n",
    "np.random.seed(4)\n",
    "segments = np.linspace(0, 1, 17)\n",
    "sampled_indices = []\n",
    "fds = []\n",
    "for i in range(len(segments) - 1):\n",
    "    lower, upper = segments[i], segments[i + 1] # Find indices where values are within the current segment\n",
    "    indices = np.argwhere((d >= lower) & (d < upper)) # If there are valid indices, randomly select one\n",
    "    if len(indices) > 0:\n",
    "        chosen_index = indices[np.random.choice(len(indices))]\n",
    "        sampled_indices.append(chosen_index)\n",
    "        fds.append(float(d[chosen_index]))\n",
    "# Convert sampled indices to a numpy array for convenience\n",
    "sampled_indices = np.array(sampled_indices)\n",
    "fds = np.array(fds)\n",
    "print(\"chosen feature dispersity values:\", fds)\n",
    "\n",
    "img_0index = np.load(folder_path + \"V4DT/top9_0index.npy\")\n",
    "img_0index = img_0index[roi!=0] # (3048, 9)\n",
    "# create a blank map of black color (R=0, G=0, B=0)\n",
    "unit_num = len(sampled_indices)\n",
    "img_size = 60\n",
    "line_width = 3\n",
    "img_num = 7 # top imgs to be displayed\n",
    "sr = 10 # surround width\n",
    "map = np.zeros((img_num * img_size + (img_num - 1) * line_width + 2 * sr,\n",
    "                unit_num * img_size + (unit_num - 1) * line_width + 2 * sr, \n",
    "                3))\n",
    "# Fill the map with the images\n",
    "for i in range(len(sampled_indices)):\n",
    "    idx = sampled_indices[i]\n",
    "    imgs = img_0index[idx, :img_num]\n",
    "    for j in range(img_num):\n",
    "        path = folder_path + \"50K_Imgset/\" + str(int(imgs[0][j] + 1)) + \".bmp\" # the image name is 1-indexed\n",
    "        img = np.array(Image.open(path))[20:80, 20:80, :] # obtain the non-blurred central part of the image\n",
    "        img = resize(img, (img_size, img_size, 3), anti_aliasing=True) # resize the image\n",
    "        # img = np.fliplr(np.flipud(img)) # flip the image vertically and horizontally\n",
    "        map[(sr + j * (img_size + line_width)) : (sr + j * (img_size + line_width) + img_size),\n",
    "            (sr + i * (img_size + line_width)) : (sr + i * (img_size + line_width) + img_size), \n",
    "            :] = img\n",
    "\n",
    "plt.imshow(map)\n",
    "plt.axis('off')  # Turn off the axis\n",
    "plt.tight_layout()\n",
    "plt.savefig(folder_path + \"Fig1/fd_img.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning curve shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning curve comparison figure\n",
    "# Compare the tuning curves of V4 digital twin benchmark and the learned SOM\n",
    "# Load the V4 digital twin responses to 50k images\n",
    "response = np.load(folder_path + \"V4DT/PRsp.npy\")\n",
    "roi = np.load(folder_path + \"V4DT/ROI.npy\").T # (128, 128) <class 'numpy.ndarray'>\n",
    "v4_benchmark = response[:, roi == 1] # (50000, 128, 128) into (50000, 3048)\n",
    "print(v4_benchmark.shape) # (50000, 3048)\n",
    "v4_benchmark = np.sort(v4_benchmark, axis=0)[::-1]  # Sort each column along rows (flip for descending order)\n",
    "print(v4_benchmark.shape) # (50000, 3048)\n",
    "v4_mean = np.mean(v4_benchmark, axis=1) # mean tuning curve\n",
    "v4_std = np.std(v4_benchmark, axis=1) # tuning curve std\n",
    "index = []\n",
    "for i in range(v4_benchmark.shape[1]):\n",
    "    assert len(v4_benchmark[:, i]) == 50000\n",
    "    half = (np.max(v4_benchmark[:, i]) - np.min(v4_benchmark[:, i])) / 2\n",
    "    for j in range(50000):\n",
    "        if v4_benchmark[j, i] <= half:\n",
    "            index.append(j)\n",
    "            break\n",
    "print(\"V4 half:\", np.mean(index), np.std(index))\n",
    "\n",
    "name_all = [\"RSOM\", \"SOM\"]\n",
    "for name in name_all:\n",
    "    rsp = np.load(folder_path + name + \"/weights.npy\")\n",
    "    if rsp.shape[2] > 50000: rsp = rsp[:, :, :-int(rsp.shape[2] - 50000)] # now rsp / som weights has shape (60, 60, 50000)\n",
    "    rsp = rsp.reshape(-1, rsp.shape[2]) # (3600, 50000)\n",
    "    rsp = np.sort(rsp.T, axis=0)[::-1]  # Sort each column along rows (flip for descending order), (50000, 3600)\n",
    "    rsp_mean = np.mean(rsp, axis=1) # mean tuning curve\n",
    "    rsp_std = np.std(rsp, axis=1) # tuning curve std\n",
    "    # normalize every tuning curve\n",
    "    index = []\n",
    "    for i in range(rsp.shape[1]):\n",
    "        assert len(rsp[:, i]) == 50000\n",
    "        half = (np.max(rsp[:, i]) - np.min(rsp[:, i])) / 2\n",
    "        for j in range(50000):\n",
    "            if rsp[j, i] <= half:\n",
    "                index.append(j)\n",
    "                break\n",
    "    # visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    print(\"V4 and simulated tuning curve correlation: {:.3f}\".format(pearsonr(np.concatenate((v4_mean, v4_std)), np.concatenate((rsp_mean, rsp_std)))[0]))\n",
    "    axes[0].plot(v4_mean, color='black')\n",
    "    axes[0].fill_between(range(len(v4_mean)), v4_mean - v4_std, v4_mean + v4_std, color='black', alpha=0.3)\n",
    "    axes[0].set_xticks([])\n",
    "    axes[0].set_yticks([])\n",
    "    axes[0].set_xlabel('50K imgs', fontsize=16)\n",
    "    axes[0].set_ylabel('response', fontsize=16)\n",
    "    axes[0].set_title('V4', fontsize=18)\n",
    "    axes[1].plot(rsp_mean, color='gray')\n",
    "    axes[1].fill_between(range(len(rsp_mean)), rsp_mean - rsp_std, rsp_mean + rsp_std, color='gray', alpha=0.3)\n",
    "    axes[1].set_xticks([])\n",
    "    axes[1].set_yticks([])\n",
    "    axes[1].set_xlabel('50K imgs', fontsize=16)\n",
    "    axes[1].set_title(\"simulation\", fontsize=18)\n",
    "    fig = plt.gcf()\n",
    "    plt.tight_layout()\n",
    "    plt.close()\n",
    "    fig.savefig(folder_path + name + \"/tunings.png\", dpi=1000)\n",
    "    del rsp, rsp_mean, rsp_std\n",
    "print(\"number of images at half maximum activation value\", np.mean(index), np.std(index))\n",
    "del v4_benchmark, v4_mean, v4_std, name_all, name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
